{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality#dictionaries-word-lists-and-patterns\n",
    "2. https://stackoverflow.com/questions/9480013/image-processing-to-improve-tesseract-ocr-accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scaling to the right size\n",
    "2. Increase contrast\n",
    "3. Binarize image\n",
    "4. remove noise and scanning artefacts (black border)\n",
    "5. Deskew\n",
    "6. Remove border"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Image processing\n",
    "2. Rescaling\n",
    "3. Binarisation\n",
    "4. Noise Removal\n",
    "5. Rotation / Deskewing\n",
    "6. Borders\n",
    "7. Transparency / Alpha channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import cv2\n",
    "import glob\n",
    "import imutils\n",
    "import tempfile\n",
    "import dateparser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import pytesseract as pt\n",
    "from datefinder import find_dates\n",
    "from dateutil.parser import parse\n",
    "from matplotlib import pyplot as plt\n",
    "from dateparser.search import search_dates\n",
    "from imutils.perspective import four_point_transform\n",
    "pt.pytesseract.tesseract_cmd = 'C:/Program Files/Tesseract-OCR/tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('image_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_str = pt.image_to_string(\"images/15.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open('images/15.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('images/4.jpeg',0)\n",
    "img = cv.medianBlur(img,5)\n",
    "ret,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY)\n",
    "th2 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C,cv.THRESH_BINARY,11,2)\n",
    "th3 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,cv.THRESH_BINARY,11,2)\n",
    "titles = ['Original Image', 'Global Thresholding (v = 127)',\n",
    "            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n",
    "images = [img, th1, th2, th3]\n",
    "plt.figure(figsize=(20,20))\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image in GRAYSCALE and apply Gaussian Blur\n",
    "img = cv.imread('images/4.jpeg',0)\n",
    "#blr = cv.GaussianBlur(img,(5,5),0)\n",
    "#Image.fromarray(img)\n",
    "img.shape  #, blr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge = cv.Canny(blr, 75, 200)\n",
    "Image.fromarray(blr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the Image size\n",
    "img = cv.resize(img, None, fx=1.5, fy=1.5, interpolation=cv.INTER_CUBIC)\n",
    "Image.fromarray(img)\n",
    "#img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 4\n",
    "rows = 5\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = np.random.randint(10, size=(h,w))\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(args[\"image\"])\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edged = cv2.Canny(blurred, 75, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/15.jpeg')\n",
    "print(img.shape)\n",
    "img_str = pt.image_to_string(Image.fromarray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale the image, if needed.\n",
    "#img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)  Enlarge the image\n",
    "#img = cv2.resize(img, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA) Shrinking \n",
    "# img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)  Trade off\n",
    "\n",
    "# Blurring image\n",
    "#img = cv.blur(img,(5,5)) Average blurr\n",
    "#img = cv2.GaussianBlur(img, (5, 5), 0) Gaussian blur\n",
    "#img = cv2.medianBlur(img, 3) median blurr\n",
    "#img = cv.bilateralFilter(img,9,75,75) keep edges sharpe\n",
    "\n",
    "img_resize = cv2.resize(img, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_CUBIC)\n",
    "img_resize.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to gray\n",
    "img_grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply dilation and erosion to remove some noise\n",
    "kernel = np.ones((1, 1), np.uint8)\n",
    "img_dilate = cv2.dilate(img_grayscale, kernel, iterations=1)\n",
    "img_erode = cv2.erode(img_dilate, kernel, iterations=1)\n",
    "\n",
    "# Apply blur to smooth out the edges\n",
    "img_gauss = cv2.GaussianBlur(img_erode, (5, 5), 0)\n",
    "\n",
    "# Thresholding\n",
    "#cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image.fromarray(img_gauss)\n",
    "#Image.open('152.jpeg')\n",
    "img_str = pt.image_to_string('152.jpeg')\n",
    "print(img_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('images/4.jpeg')\n",
    "img_thres = cv2.threshold(img,117,255,cv2.THRESH_BINARY)[1]\n",
    "Image.fromarray(img_thres)\n",
    "#img_str = pt.image_to_string(img_thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply threshold to get image with only b&w (binarization)\n",
    "img_thres = cv2.threshold(img_gauss, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(img_thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set image DPI  (It reduce the size of image)\n",
    "def set_image_dpi(file_path):\n",
    "    im = Image.open(file_path)\n",
    "    length_x, width_y = im.size \n",
    "    factor = min(1, float(1024.0 / length_x)) \n",
    "    size = int(factor * length_x), int(factor * width_y) \n",
    "    im_resized = im.resize(size, Image.ANTIALIAS)\n",
    "    return im_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img = set_image_dpi(\"images/13.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('images/1.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.cvtColor(np.array(new_img.resize((500,500), Image.ANTIALIAS)), cv2.COLOR_BGR2GRAY)\n",
    "cv2.resize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Detect the text block with skew in the image.\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edged = cv2.Canny(gray, 10, 50)\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "#cnts = cnts[0] if imutils.is_cv2() else cnts[1]\n",
    "cnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:5]\n",
    "\n",
    "screenCnt = None\n",
    "for c in cnts:\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "    if len(approx) == 4:\n",
    "        screenCnt = approx\n",
    "        break\n",
    "        \n",
    "img_drawcnt = cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(img_drawcnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Now calculate the angle of rotation.\n",
    "# 3. Rotating the image to correct the skew.\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_str = pt.image_to_string('new.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image.open('images/13.jpeg') # 250,250\n",
    "image = cv2.imread(\"images/13.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = img_drawcnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Detecting skewness and rotate image\n",
    "\n",
    "#image = cv2.imread(\"images/46.jpeg\")\n",
    "\n",
    "# convert the image to grayscale and flip the foreground\n",
    "# and background to ensure foreground is now \"white\" and\n",
    "# the background is \"black\"\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.bitwise_not(gray)\n",
    " \n",
    "# threshold the image, setting all foreground pixels to\n",
    "# 255 and all background pixels to 0\n",
    "thresh = cv2.threshold(gray, 0, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# Finding minimum rotated bouding region\n",
    "# grab the (x, y) coordinates of all pixel values that\n",
    "# are greater than zero, then use these coordinates to\n",
    "# compute a rotated bounding box that contains all\n",
    "# coordinates\n",
    "coords = np.column_stack(np.where(thresh > 0))\n",
    "angle = cv2.minAreaRect(coords)[-1]\n",
    " \n",
    "# the `cv2.minAreaRect` function returns values in the\n",
    "# range [-90, 0); as the rectangle rotates clockwise the\n",
    "# returned angle trends to 0 -- in this special case we\n",
    "# need to add 90 degrees to the angle\n",
    "if angle < -45:\n",
    "    angle = -(90 + angle)\n",
    "\n",
    "# otherwise, just take the inverse of the angle to make\n",
    "# it positive\n",
    "else:\n",
    "    angle = -angle\n",
    "    \n",
    "# rotate the image to deskew it\n",
    "(h, w) = image.shape[:2]\n",
    "center = (w // 2, h // 2)\n",
    "M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "rotated = cv2.warpAffine(image, M, (w, h),flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "# draw the correction angle on the image so we can validate it\n",
    "cv2.putText(rotated, \"Angle: {:.2f} degrees\".format(angle),\n",
    "    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    " \n",
    "# show the output image\n",
    "print(\"[INFO] angle: {:.3f}\".format(angle))\n",
    "cv2.imshow(\"Input\", image)\n",
    "cv2.imshow(\"Rotated\", rotated)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectify(h):\n",
    "    h = h.reshape((4,2))\n",
    "    hnew = np.zeros((4,2),dtype = np.float32)\n",
    "\n",
    "    add = h.sum(1)\n",
    "    hnew[0] = h[np.argmin(add)]\n",
    "    hnew[2] = h[np.argmax(add)]\n",
    "\n",
    "    diff = np.diff(h,axis = 1)\n",
    "    hnew[1] = h[np.argmin(diff)]\n",
    "    hnew[3] = h[np.argmax(diff)]\n",
    "\n",
    "    return hnew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_str = pt.image_to_string(Image.open('images/31.jpeg'))\n",
    "print(img_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This combination works\n",
    "1. Rescalling with 2 factor\n",
    "2. Change to grayscale\n",
    "3. Either we do binarize then remove noise / remove noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_filter = (3,3)\n",
    "img = cv2.imread('images/4.jpeg') # 450,338,3\n",
    "image = cv2.resize(img, None, fx = 2, fy = 2, interpolation=cv2.INTER_CUBIC) \n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, gaussian_filter, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_str = pt.image_to_string(Image.fromarray(blurred))\n",
    "print(img_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types of filter to remove noise\n",
    "\n",
    "#img_blur = cv.blur(img,(5,5)) Average blurr\n",
    "#img      = cv2.GaussianBlur(img, (5, 5), 0) Gaussian blur\n",
    "#img      = cv2.medianBlur(img, 3) median blurr\n",
    "#img   = cv2.bilateralFilter(gray,9,75,75) \n",
    "ret2,th4 = cv2.threshold(blurred,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "ret,th1 = cv2.threshold(blurred,100,200,cv2.THRESH_BINARY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_str = pt.image_to_string('images/4.jpeg')\n",
    "print(img_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seems threshold doesn't give good accracy on some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_dates(\"29-MAY -2019\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Image.fromarray(blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nret,thresh1 = cv2.threshold(dst,127,255,cv2.THRESH_BINARY)\\nret,thresh2 = cv2.threshold(dst,127,255,cv2.THRESH_BINARY_INV)\\nret,thresh3 = cv2.threshold(dst,127,255,cv2.THRESH_TRUNC)\\nret,thresh4 = cv2.threshold(dst,127,255,cv2.THRESH_TOZERO)\\nret,thresh5 = cv2.threshold(dst,127,255,cv2.THRESH_TOZERO_INV)\\n\\ncv2.imshow(\"Thresh Binary\", thresh1)\\ncv2.imshow(\"Thresh Binary_INV\", thresh2)\\ncv2.imshow(\"Thresh Trunch\", thresh3)\\ncv2.imshow(\"Thresh TOZERO\", thresh4)\\ncv2.imshow(\"Thresh TOZERO_INV\", thresh5)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_filter = (3,3)\n",
    "img = cv2.imread('images/4.jpeg') # 450,338,3\n",
    "image = cv2.resize(img, None, fx = 2, fy = 2, interpolation=cv2.INTER_CUBIC) \n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, gaussian_filter, 0)\n",
    "\n",
    "# creating copy of original image\n",
    "orig = image.copy()\n",
    "\n",
    "# convert to grayscale and blur to smooth\n",
    "#blurred = cv2.medianBlur(gray, 5)\n",
    "\n",
    "# apply Canny Edge Detection\n",
    "edged = cv2.Canny(blurred, 0, 50)\n",
    "orig_edged = edged.copy()\n",
    "\n",
    "# find the contours in the edged image, keeping only the\n",
    "# largest ones, and initialize the screen contour\n",
    "(contours, _) = cv2.findContours(edged, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "#x,y,w,h = cv2.boundingRect(contours[0])\n",
    "#cv2.rectangle(image,(x,y),(x+w,y+h),(0,0,255),0)\n",
    "\n",
    "# get approximate contour\n",
    "for c in contours:\n",
    "    p = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * p, True)\n",
    "\n",
    "    if len(approx) == 4:\n",
    "        target = approx\n",
    "        break\n",
    "\n",
    "\n",
    "# mapping target points to 800x800 quadrilateral\n",
    "approx = rectify(target)\n",
    "pts2 = np.float32([[0,0],[800,0],[800,800],[0,800]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(approx,pts2)\n",
    "dst = cv2.warpPerspective(orig,M,(800,800))\n",
    "\n",
    "cv2.drawContours(image, [target], -1, (0, 255, 0), 2)\n",
    "dst = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# using thresholding on warped image to get scanned effect (If Required)\n",
    "th2 = cv2.adaptiveThreshold(dst,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n",
    "th3 = cv2.adaptiveThreshold(dst,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "ret2,th4 = cv2.threshold(dst,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "ret,th1 = cv2.threshold(dst,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "#cv2.imshow(\"Original\", orig)\n",
    "#cv2.imshow(\"Original Gray\", gray)\n",
    "#cv2.imshow(\"Original Blurred\", blurred)\n",
    "#cv2.imshow(\"Original Edged\", orig_edged)\n",
    "#cv2.imshow(\"Outline\", image)\n",
    "#cv2.imshow(\"Thresh Binary\", th1)\n",
    "#cv2.imshow(\"Thresh mean\", th2)\n",
    "#cv2.imshow(\"Thresh gauss\", th3)\n",
    "#cv2.imshow(\"Otsu's\", th4)\n",
    "#cv2.imshow(\"dst\", dst)\n",
    "\n",
    "# other thresholding methods\n",
    "\"\"\"\n",
    "ret,thresh1 = cv2.threshold(dst,127,255,cv2.THRESH_BINARY)\n",
    "ret,thresh2 = cv2.threshold(dst,127,255,cv2.THRESH_BINARY_INV)\n",
    "ret,thresh3 = cv2.threshold(dst,127,255,cv2.THRESH_TRUNC)\n",
    "ret,thresh4 = cv2.threshold(dst,127,255,cv2.THRESH_TOZERO)\n",
    "ret,thresh5 = cv2.threshold(dst,127,255,cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "cv2.imshow(\"Thresh Binary\", thresh1)\n",
    "cv2.imshow(\"Thresh Binary_INV\", thresh2)\n",
    "cv2.imshow(\"Thresh Trunch\", thresh3)\n",
    "cv2.imshow(\"Thresh TOZERO\", thresh4)\n",
    "cv2.imshow(\"Thresh TOZERO_INV\", thresh5)\n",
    "\"\"\"\n",
    "\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3053"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So, Ultimately we come to know that-\n",
    "## 1. Rescaling the image to 2 factor\n",
    "## 2. Convert it to grayscale color\n",
    "## 3. Apply gaussain filter to remove noises\n",
    "\n",
    "## After applying so many filters we came to know:\n",
    "## 1. Contour doesn't works on few images it \n",
    "## 2. Threshold also doesn't works\n",
    "\n",
    "## Now we check accuracy on first 100 images after applying these transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_date(img_ar):\n",
    "    img_str = pt.image_to_string(Image.fromarray(img_ar))\n",
    "    newstr = list(set(map(lambda x : x.strip(), img_str.split('\\n'))))\n",
    "    tags = []\n",
    "    for i in newstr:\n",
    "        try:\n",
    "            find_date = search_dates(i) \n",
    "        except:\n",
    "            continue\n",
    "        if find_date:\n",
    "            for j in find_date:\n",
    "                tags.append(j[0])\n",
    "\n",
    "    pattern1 = r\"(\\d{1,4}([.'’\\-/])\\d{1,2}([.'’\\-/])\\d{1,4})\"\n",
    "    pattern2 = r\"(\\d{1,4}([.'’\\-/\\s])[ADFJMNOSadfjmnos]\\w*([.'’\\-/\\s]*)\\d{1,4})\"\n",
    "    pattern3 = r\"([ADFJMNOSadfjmnos]\\w*\\s\\d{1,4}([,'’.\\-/\\s]*)([.'’\\-/\\s])\\d{1,4})\"\n",
    "    pattern4 = r\"[ADFJMNOSadfjmnos]\\w*\\d{1,4}(['’]*)\\d{1,4}\"\n",
    "    pattern5 = r\"(\\d{1,4}([.'’\\-/\\s])\\d{1,4}\"\n",
    "    \n",
    "    date_find = []\n",
    "\n",
    "    for i in tags:\n",
    "        for j in (re.search(regex,i) for regex in [pattern1, pattern2, pattern3, pattern4]):\n",
    "            if j:\n",
    "                s = j.group()\n",
    "                if s.find('.'):\n",
    "                    date_find.append(\"-\".join(s.split('.')))\n",
    "                else:\n",
    "                    date_find.append(s)\n",
    "\n",
    "    date_find = list(set(date_find))\n",
    "\n",
    "    dates = {}\n",
    "    for i in date_find:\n",
    "        try:\n",
    "            dates[i] = search_dates(i)[0][1].strftime(\"%Y-%m-%d\")\n",
    "        except:\n",
    "            continue\n",
    "    print(dates)\n",
    "    if dates:\n",
    "        #print(min(dates.values()))\n",
    "        return min(dates.values())\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finding_date('images/4.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepreprocess(path):\n",
    "    gaussian_filter = (3,3)\n",
    "    img = cv2.imread(path) \n",
    "    img = cv2.resize(img, None, fx = 2, fy = 2, interpolation=cv2.INTER_CUBIC) \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.GaussianBlur(img, gaussian_filter, 0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = prepreprocess('images/1.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.columns = ['images', 'actual', 'converted', 'predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['predicted_2'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the images which either dont have dates or not readable by human eye\n",
    "raw.images[raw.actual.isna()].values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in raw.images:\n",
    "    path = \"images/\" + str(i) + \".jpeg\"\n",
    "    print(i,end=' : ')\n",
    "    img_arr  = prepreprocess(path)\n",
    "    date = finding_date(img_arr)\n",
    "    raw.loc[i,'predicted_2'] = date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Point to remember"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"images/68.jpeg\"\n",
    "img_str = pt.image_to_string(path, lang='eng')\n",
    "print(img_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_filter = (5,5)\n",
    "img = cv2.imread(path) \n",
    "image = cv2.resize(img, None, fx = 2, fy = 2, interpolation=cv2.INTER_CUBIC) \n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, gaussian_filter, 0)\n",
    "\n",
    "img_str = pt.image_to_string(Image.fromarray(blurred))\n",
    "print(img_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This combination works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_filter = (5,5)\n",
    "img = cv2.imread(path) \n",
    "img = cv2.resize(img, None, fx = 2, fy = 2, interpolation=cv2.INTER_CUBIC) \n",
    "img_grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "kernel = np.ones((1, 1), np.uint8)\n",
    "img_dilate = cv2.dilate(img_grayscale, kernel, iterations=1)\n",
    "img_erode = cv2.erode(img_dilate, kernel, iterations=1)\n",
    "img_gauss = cv2.GaussianBlur(img_erode, gaussian_filter, 0)\n",
    "\n",
    "\n",
    "# Thresholding\n",
    "img_thres = cv2.adaptiveThreshold(img_gauss, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "\n",
    "img_str = pt.image_to_string(Image.fromarray(img_thres),lang='eng')\n",
    "print(img_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Also, this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret2,th4 = cv2.threshold(img_gauss,0,225,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "ret,th1 = cv2.threshold(img_gauss,100,220,cv2.THRESH_BINARY)\n",
    "#Image.fromarray(th1)\n",
    "print(pt.image_to_string(Image.fromarray(th4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(th4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_raw = raw[raw.actual.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_raw.converted\n",
    "#new_raw.loc['predicted_2'] = new_raw.loc['predicted_2'][1:]\n",
    "#new_raw#.loc['predicted_3'] = \n",
    "#new_raw['predicted_3'] = ns[1:].values\n",
    "#new_raw.drop(['predicted','predicted_2'],axis=1,inplace=True)\n",
    "#new_raw.predicted_3 == new_raw.converted).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(new_raw.predicted_2 == new_raw.converted).value_counts()\n",
    "new_raw.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 48 % accuracy on 2nd attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def globalpreprocess(path):\n",
    "    \n",
    "    img_str_1 = pt.image_to_string(path, lang='eng')\n",
    "    \n",
    "    gaussian_filter = (3,3)\n",
    "    img = cv2.imread(path) \n",
    "    img = cv2.resize(img, None, fx = 3, fy = 3, interpolation=cv2.INTER_CUBIC) \n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_blur = cv2.GaussianBlur(img_gray, gaussian_filter, 0)\n",
    "    img_str_2 = pt.image_to_string(Image.fromarray(img_blur),lang =\"eng\")\n",
    "    \n",
    "    img_ad_thres = cv2.adaptiveThreshold(img_blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "    img_str_3 = pt.image_to_string(Image.fromarray(img_ad_thres),lang='eng')\n",
    "\n",
    "    ret,th1 = cv2.threshold(img_blur, 100, 225, cv2.THRESH_BINARY)\n",
    "    img_str_4 = pt.image_to_string(Image.fromarray(th1), lang = 'eng')\n",
    "\n",
    "    return [img_str_1,img_str_2,img_str_3,img_str_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'images/38.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = globalpreprocess(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vea reuy earns\n",
      "LPPRTAR TARP #\n",
      "a) ew\n",
      ": fy 7 L/P\n",
      "ne 7,\n",
      "4 Py Ea Oye\n",
      "wee\n",
      "a\"\n",
      "\n",
      "eR ao .\n",
      "\n",
      "5 PRY) RPE SRD PRP\n",
      "\n",
      "SURE E DE se\n",
      "RR DED RD RR DIRY)\n",
      "\n",
      "USED NURMEUENS\n",
      "SORTER OPRDER Bs\n",
      "ih fF\n",
      "\n",
      "ROE\n",
      "BON\n",
      "\n",
      "P\n",
      "4\n",
      "eS\n",
      "\n",
      "Her\n",
      "\n",
      "s fee\n",
      "i\n",
      "\n",
      "VERON\n",
      "\n",
      "            \n",
      "\n",
      ". ae —L\n",
      "Lomo\n",
      "| VS\n",
      "—_—,,\n",
      "ot\n",
      "it Lol\n",
      "_n o—™\n",
      "~~ 4\n",
      "art. a\n",
      "SLs Sf:\n",
      "tr f i 1 od\n",
      "ma <<\n",
      "on\n",
      "——\n",
      "\n",
      "ay Pa om cy)\n",
      "ai teen ORT\n",
      "SG GGUS\n",
      "+ ps i\n",
      "RCAC ROR SEIN He)\n",
      "\n",
      ":\n",
      "TARE N\n",
      "\n",
      "ey\n",
      "\n",
      "7)\n",
      "\n",
      "i\n",
      "PRES]\n",
      "\n",
      "a\n",
      "\n",
      " \n",
      "\n",
      "f\n",
      "\n",
      "ICSQL7S7\n",
      "(-\n",
      "\n",
      "(\n",
      "\n",
      "Tena\n",
      "SL\n",
      "\n",
      "CRE SE\n",
      "bf [at\n",
      "mR Wee\n",
      "een om % A\n",
      "ROR\n",
      "\n",
      "fa\n",
      "AOR\n",
      "\n",
      "WRU\n",
      "\n",
      "ae\n",
      "\n",
      " \n",
      "\n",
      "Dd\n",
      "\n",
      "‘3\n",
      "\n",
      "HEHEME SSI\n",
      "Sik Sh\n",
      "Rss PERN\n",
      "\n",
      "*\n",
      "\n",
      "1\n",
      "\n",
      "_\n",
      "\n",
      "’\n",
      "|\n",
      "\n",
      "¢\n",
      ")\n",
      "\n",
      "i2D\n",
      "t\n",
      "\n",
      "200\n",
      "\n",
      "ce\n",
      "\n",
      "cf\n",
      "\n",
      "A\n",
      "\n",
      "5\n",
      "\n",
      "de\n",
      "Ap\n",
      "\n",
      "f\n",
      "\n",
      "A\n",
      "\n",
      ".\n",
      "3\n",
      "\n",
      "“\n",
      "X\n",
      "\n",
      "it\n",
      "\n",
      "1\n",
      "eesnsne\n",
      "\n",
      "q\n",
      "\n",
      "©\n",
      "\n",
      "«>\n",
      "\n",
      "wVTY\n",
      "\n",
      " \n",
      "\n",
      "\\. ra\n",
      "© LP\n",
      "\n",
      "-\n",
      "aed.\n",
      "\n",
      "Ary\n",
      "\n",
      "S a“ os ¢\n",
      "!\n",
      "\n",
      "A\n",
      "\n",
      "¢\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "¢\n",
      "\n",
      "Cd 5 a. oR\n",
      "\n",
      "ESN\n",
      "\n",
      "A i? 3 i\n",
      "OEE OL DEE ne tis\n",
      "\n",
      "SEES SEN\n"
     ]
    }
   ],
   "source": [
    "print(ll[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ee\n",
      "OTH\n",
      "\n",
      "ita\n",
      "\n",
      "bh Oe ASP RL\n",
      "4 ey ifs\n",
      "ries\n",
      "ira\n",
      "TI TIRT HS\n",
      "ashe\n",
      "ee Va\n",
      "\n",
      "* Te\n",
      "\n",
      "TTI\n",
      "PLT PT DAL eh bs\n",
      "CTP ESTP TD,\n",
      "\n",
      "NB et alee,\n",
      "PELLET,\n",
      "See,\n",
      "\n",
      "oi\n",
      "Signleg hs\n",
      "\n",
      "c\n",
      "i\n",
      "\n",
      "’\n",
      "\n",
      "44\n",
      "\n",
      "YH CA\n",
      "\n",
      "P.C,.H HWY\n",
      "RT BEAC\n",
      "\n",
      "E..\n",
      "92660\n",
      "\n",
      "301\n",
      "NEWP(¢\n",
      "\n",
      "             \n",
      "\n",
      "  \n",
      "  \n",
      "\n",
      "9\n",
      "\n",
      "0.465\n",
      "\n",
      "7\n",
      "\n",
      "LIAO\n",
      "\n",
      "5935\n",
      "¢ 79,\n",
      "\n",
      "CA\n",
      "5\n",
      "$3 .899\n",
      "\n",
      "3\n",
      "at\n",
      "age\n",
      "\n",
      "ON\n",
      "t\n",
      "OV\n",
      "as\n",
      "i G\n",
      "Ce 7 OV © N oO aH\n",
      "on a © Omics A i A a cao\n",
      "= FO — N t O30 8 2\n",
      "im WN = «~ AN iW Divers\n",
      "pkey) ete] OO oS ~O OO = T—--4-T\n",
      "© om rr os. LN Hj << os Lo S<t vO\n",
      "th~©O OR 3s SOc <c f= wo O-4 O\n",
      "In10> ES Nt 3. NO OS a BH CCW\n",
      "Aina ~ 9° “PSGOLOS 2 ONC Os OL©\n",
      "—rh) oO LQ): “esas Te (xj ci. Sy CS\n",
      "QMO A. NO KesOm AWO _) oO, SSapecas\n",
      "> N43 Sco pSDdSer SU l— = 8 [f) l-a +P ODODOL\n",
      "coo Ot KZ DSM DS mF VFElvd\n",
      "MOmnz © Py Sarees iL, fT. CCS) <> EC)\n",
      "\n",
      " \n",
      " \n",
      " \n",
      "\n",
      " \n",
      "\n",
      "eee\n",
      "ae\n",
      "PS\n",
      "\n",
      "tear\n",
      "Pee)\n",
      "PEI PS\n"
     ]
    }
   ],
   "source": [
    "print(ll[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
