{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing terms\n",
    "\n",
    "1. Scaling to the right size\n",
    "2. Increase contrast\n",
    "3. Binarize image\n",
    "4. remove noise and scanning artefacts (black border)\n",
    "5. Deskew\n",
    "6. Remove border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import cv2\n",
    "import glob\n",
    "import imutils\n",
    "import tempfile\n",
    "import argparse\n",
    "import dateparser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import pytesseract as pt\n",
    "from imutils import contours\n",
    "from datefinder import find_dates\n",
    "from dateutil.parser import parse\n",
    "from matplotlib import pyplot as plt\n",
    "from dateparser.search import search_dates\n",
    "from imutils.perspective import four_point_transform\n",
    "pt.pytesseract.tesseract_cmd = 'C:/Program Files/Tesseract-OCR/tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"images/4.jpeg\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edged = cv2.Canny(blurred, 75, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# find contours in the edge map, then initialize\n",
    "# the contour that corresponds to the document\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "docCnt = None\n",
    " \n",
    "# ensure that at least one contour was found\n",
    "if len(cnts) > 0:\n",
    " # sort the contours according to their size in\n",
    "# descending order\n",
    "    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    " \n",
    "    # loop over the sorted contours\n",
    "for c in cnts:\n",
    "    # approximate the contour\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    " \n",
    "    # if our approximated contour has four points,\n",
    "    # then we can assume we have found the paper\n",
    "    if len(approx) == 4:\n",
    "        docCnt = approx\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a four point perspective transform to both the\n",
    "# original image and grayscale image to obtain a top-down\n",
    "# birds eye view of the paper\n",
    "paper = four_point_transform(image, docCnt.reshape(4, 2))\n",
    "warped = four_point_transform(gray, docCnt.reshape(4, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = cv2.threshold(warped, 0, 255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = r\"(\\d{1,4}([.'’\\-/])\\d{1,2}([.'’\\-/])\\d{1,4})\"\n",
    "pattern2 = r\"(\\d{1,4}([.'’\\-/\\s])[ADFJMNOSadfjmnos]\\w*([.'’\\-/\\s]*)\\d{1,4})\"\n",
    "pattern3 = r\"([ADFJMNOSadfjmnos]\\w*\\s\\d{1,4}([,'’.\\-/\\s]*)([.'’\\-/\\s])\\d{1,4})\"\n",
    "pattern4 = r\"[ADFJMNOSadfjmnos]\\w*\\d{1,4}(['’]*)\\d{1,4}\"\n",
    "pattern5 = r\"(\\d{1,4}([.'’\\-/\\s])\\d{1,4}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spread(arg):\n",
    "    ret = []\n",
    "    for i in arg:\n",
    "        if isinstance(i, list):\n",
    "            ret.extend(i)\n",
    "        else:\n",
    "            ret.append(i)\n",
    "    return ret\n",
    "\n",
    "def deep_flatten(lst):\n",
    "    result = []\n",
    "    result.extend(spread(list(map(lambda x: deep_flatten(x) if type(x) == list else x, lst))))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_date(img_str):\n",
    "    imstr = img_str\n",
    "    pattern1 = r\"(\\d{1,4}([.'’\\-/])\\d{1,2}([.'’\\-/])\\d{1,4})\"\n",
    "    pattern2 = r\"(\\d{1,4}([.'’\\-/\\s])[ADFJMNOSadfjmnos]\\w*([.'’\\-/\\s]*)\\d{1,4})\"\n",
    "    pattern3 = r\"([ADFJMNOSadfjmnos]\\w*\\s\\d{1,4}([,'’.\\-/\\s]*)([.'’\\-/\\s])\\d{1,4})\"\n",
    "    pattern4 = r\"[ADFJMNOSadfjmnos]\\w*\\d{1,4}(['’]*)\\d{1,4}\"\n",
    "    pattern5 = r\"(\\d{1,4}([.'’\\-/\\s])\\d{1,4}\"\n",
    "    \n",
    "    date_find = []\n",
    "\n",
    "    for i in imstr:\n",
    "        for j in (re.search(regex,i) for regex in [pattern1, pattern2, pattern3, pattern4]):\n",
    "            if j:\n",
    "                s = j.group()\n",
    "                if s.find('.'):\n",
    "                    date_find.append(\"-\".join(s.split('.')))\n",
    "                else:\n",
    "                    date_find.append(s)\n",
    "\n",
    "    date_find = list(set(date_find))\n",
    "\n",
    "    dates = []\n",
    "    for i in date_find:\n",
    "        try:\n",
    "            #dates.append(search_dates(i)[0][1].strftime(\"%Y-%m-%d\"))\n",
    "            dates.append(parse(i).strftime(\"%Y-%m-%d\"))   \n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    dates = set(dates)\n",
    "    \n",
    "    new_dates = []\n",
    "    for i in dates:\n",
    "        if 2010 < int(i[:4]) < 2020:\n",
    "            new_dates.append(i)\n",
    "    print(new_dates)\n",
    "    \n",
    "    if new_dates:\n",
    "        return max(new_dates)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instead of feeding single input image with pre-process.\n",
    "# Now, I'm going to feed more than 4 same image with differently pre-processed.Also called Stacking technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def globalpreprocess(path):\n",
    "    \n",
    "    img_str_1 = pt.image_to_string(path, lang='eng')\n",
    "    \n",
    "    gaussian_filter = (5,5)\n",
    "    img = cv2.imread(path) \n",
    "    img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC) \n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_blur = cv2.GaussianBlur(img_gray, gaussian_filter, 0)\n",
    "    img_str_2 = pt.image_to_string(Image.fromarray(img_blur),lang =\"eng\")\n",
    "    \n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    img_dilate = cv2.dilate(img_gray, kernel, iterations=1)\n",
    "    img_erode = cv2.erode(img_dilate, kernel, iterations=1)\n",
    "    img_gauss = cv2.GaussianBlur(img_erode, gaussian_filter, 0)\n",
    "    #img_ad_thres = cv2.adaptiveThreshold(img_gauss, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "    #img_str_3 = pt.image_to_string(Image.fromarray(img_ad_thres),lang='eng')\n",
    "\n",
    "    ret,th1 = cv2.threshold(img_gauss, 100, 225, cv2.THRESH_BINARY)\n",
    "    img_str_4 = pt.image_to_string(Image.fromarray(th1), lang = 'eng')\n",
    "\n",
    "    return [img_str_1,img_str_2,img_str_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'images/1.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = globalpreprocess(path)\n",
    "\n",
    "z = [list(set(map(lambda x: x.strip(),img.split('\\n')))) for img in ll]\n",
    "newstr = set(deep_flatten(z))\n",
    "\n",
    "date = finding_date(newstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Without any filter\n",
    "path = \"images/68.jpeg\"\n",
    "print(pt.image_to_string(path, lang='eng'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. with filter\n",
    "# image < resize < grayscale < gaussian \n",
    "gaussian_filter = (5,5)\n",
    "img = cv2.imread(path) \n",
    "image = cv2.resize(img, None, fx = 2, fy = 2, interpolation=cv2.INTER_CUBIC) \n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, gaussian_filter, 0)\n",
    "\n",
    "print(pt.image_to_string(Image.fromarray(blurred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. with filter\n",
    "# image < resize < grayscale < gaussian < Binarization(auto)\n",
    "gaussian_filter = (5,5)\n",
    "img = cv2.imread(path) \n",
    "img = cv2.resize(img, None, fx = 2, fy = 2, interpolation=cv2.INTER_CUBIC) \n",
    "img_grayscale = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "kernel = np.ones((1, 1), np.uint8)\n",
    "img_dilate = cv2.dilate(img_grayscale, kernel, iterations=1)\n",
    "img_erode = cv2.erode(img_dilate, kernel, iterations=1)\n",
    "img_gauss = cv2.GaussianBlur(img_erode, gaussian_filter, 0)\n",
    "\n",
    "# Thresholding\n",
    "img_thres = cv2.adaptiveThreshold(img_gauss, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)\n",
    "\n",
    "print(pt.image_to_string(Image.fromarray(img_thres),lang='eng'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. with filters\n",
    "# image < resize < grayscale < gaussian < Binarization(threshold)\n",
    "ret,th1 = cv2.threshold(img_gauss,100,225,cv2.THRESH_BINARY)\n",
    "ret2,th2 = cv2.threshold(img_gauss,100,220,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "print(pt.image_to_string(Image.fromarray(th1), lang = 'eng'))\n",
    "\n",
    "# adaptive threshold doesnt works\n",
    "# also OTSU doesnt works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image.fromarray(ret2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectify(h):\n",
    "    h = h.reshape((4,2))\n",
    "    hnew = np.zeros((4,2),dtype = np.float32)\n",
    "\n",
    "    add = h.sum(1)\n",
    "    hnew[0] = h[np.argmin(add)]\n",
    "    hnew[2] = h[np.argmax(add)]\n",
    "\n",
    "    diff = np.diff(h,axis = 1)\n",
    "    hnew[1] = h[np.argmin(diff)]\n",
    "    hnew[3] = h[np.argmax(diff)]\n",
    "\n",
    "    return hnew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(path) \n",
    "image = cv2.resize(img, None, fx = 2, fy = 2, interpolation=cv2.INTER_CUBIC) \n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, gaussian_filter, 0)\n",
    "\n",
    "# creating copy of original image\n",
    "orig = image.copy()\n",
    "\n",
    "# convert to grayscale and blur to smooth\n",
    "#blurred = cv2.medianBlur(gray, 5)\n",
    "\n",
    "# apply Canny Edge Detection\n",
    "edged = cv2.Canny(blurred, 0, 50)\n",
    "orig_edged = edged.copy()\n",
    "\n",
    "# find the contours in the edged image, keeping only the\n",
    "# largest ones, and initialize the screen contour\n",
    "(contours, _) = cv2.findContours(img_thres2, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "#x,y,w,h = cv2.boundingRect(contours[0])\n",
    "#cv2.rectangle(image,(x,y),(x+w,y+h),(0,0,255),0)\n",
    "\n",
    "# get approximate contour\n",
    "for c in contours:\n",
    "    p = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * p, True)\n",
    "\n",
    "    if len(approx) == 4:\n",
    "        target = approx\n",
    "        break\n",
    "\n",
    "\n",
    "# mapping target points to 800x800 quadrilateral\n",
    "approx = rectify(target)\n",
    "pts2 = np.float32([[0,0],[800,0],[800,800],[0,800]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(approx,pts2)\n",
    "dst = cv2.warpPerspective(orig,M,(800,800))\n",
    "dst = cv2.drawContours(image, [target], -1, (0, 255, 0), 2)\n",
    "dst = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pt.image_to_string(Image.fromarray(dst)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_str = pt.image_to_string('images/38.jpeg', lang='eng')\n",
    "print(img_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('image_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>actual</th>\n",
       "      <th>converted</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>May 21, 2019</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25-07-19</td>\n",
       "      <td>2019-07-25</td>\n",
       "      <td>2019-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Sep 29, 2018</td>\n",
       "      <td>2018-09-29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Oct06' 16</td>\n",
       "      <td>2016-10-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5/29/2019</td>\n",
       "      <td>2019-05-29</td>\n",
       "      <td>2019-05-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        actual   converted   predicted\n",
       "0           1  May 21, 2019  2019-05-21         NaN\n",
       "1           2      25-07-19  2019-07-25  2019-07-25\n",
       "2           3  Sep 29, 2018  2018-09-29         NaN\n",
       "3           4     Oct06' 16  2016-10-06         NaN\n",
       "4           5     5/29/2019  2019-05-29  2019-05-29"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['predicted_2'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['images', 'actual', 'converted', 'predicted', 'predicted_2'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = raw.columns.tolist()\n",
    "z[0] = 'images'\n",
    "raw.columns = z\n",
    "raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.loc[0,'predicted_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : []\n",
      "2 : ['2019-07-25']\n",
      "3 : ['2018-09-29']\n",
      "4 : []\n",
      "5 : ['2019-05-29']\n",
      "6 : ['2019-07-03']\n",
      "7 : []\n",
      "8 : []\n",
      "9 : []\n",
      "10 : ['2019-05-22']\n",
      "11 : ['2019-07-17']\n",
      "12 : ['2019-07-02']\n",
      "13 : []\n",
      "14 : ['2019-07-22']\n",
      "15 : []\n",
      "16 : []\n",
      "17 : ['2019-05-24', '2019-08-24']\n",
      "18 : ['2016-04-15']\n",
      "19 : ['2019-02-05']\n",
      "20 : ['2019-06-20']\n",
      "21 : ['2019-05-29']\n",
      "22 : []\n",
      "23 : ['2019-05-02']\n",
      "24 : ['2019-06-18']\n",
      "25 : ['2019-06-28']\n",
      "26 : ['2019-06-03']\n",
      "27 : ['2019-06-20']\n",
      "28 : ['2019-04-13', '2019-07-12']\n",
      "29 : ['2019-06-07']\n",
      "30 : ['2019-06-28']\n",
      "31 : ['2019-04-30']\n",
      "32 : []\n",
      "33 : []\n",
      "34 : ['2019-06-08']\n",
      "35 : ['2019-07-14']\n",
      "36 : ['2018-06-30']\n",
      "37 : ['2019-06-27']\n",
      "38 : []\n",
      "39 : ['2016-11-24']\n",
      "40 : []\n",
      "41 : ['2019-06-19']\n",
      "42 : []\n",
      "43 : ['2019-09-19', '2019-05-19']\n",
      "44 : ['2019-08-07']\n",
      "45 : ['2019-05-18']\n",
      "46 : ['2014-05-22']\n",
      "47 : []\n",
      "48 : ['2015-08-22']\n",
      "49 : ['2019-08-09']\n",
      "50 : ['2019-06-27']\n",
      "51 : ['2019-07-20']\n",
      "52 : ['2019-06-02', '2019-05-22', '2019-03-02']\n",
      "53 : ['2019-07-19']\n",
      "54 : ['2019-06-01']\n",
      "55 : ['2019-07-09']\n",
      "56 : ['2013-07-06']\n",
      "57 : []\n",
      "58 : []\n",
      "59 : ['2018-10-20']\n",
      "60 : ['2018-02-17']\n",
      "61 : ['2013-06-24']\n",
      "62 : ['2019-06-06']\n",
      "63 : []\n",
      "64 : ['2019-06-01']\n",
      "65 : ['2019-06-07']\n",
      "66 : ['2019-07-04']\n",
      "67 : []\n",
      "68 : ['2019-06-01']\n",
      "69 : ['2019-06-26', '2019-06-28']\n",
      "70 : []\n",
      "71 : ['2019-06-14']\n",
      "72 : ['2019-06-25']\n",
      "73 : ['2019-06-19']\n",
      "74 : ['2019-11-07']\n",
      "75 : ['2019-04-08']\n",
      "76 : ['2019-07-01']\n",
      "77 : []\n",
      "78 : []\n",
      "79 : ['2019-06-29']\n",
      "80 : ['2019-02-05']\n",
      "81 : ['2019-03-02']\n",
      "82 : []\n",
      "83 : []\n",
      "84 : []\n",
      "85 : ['2016-05-26']\n",
      "86 : ['2019-06-29']\n",
      "87 : []\n",
      "88 : ['2019-05-17']\n",
      "89 : ['2019-07-01']\n",
      "90 : []\n",
      "91 : []\n",
      "92 : ['2019-08-30']\n",
      "93 : ['2019-06-04']\n",
      "94 : ['2015-04-25']\n",
      "95 : ['2019-07-02']\n",
      "96 : ['2013-06-18', '2019-06-15']\n",
      "97 : []\n",
      "98 : ['2019-07-02', '2019-07-03']\n",
      "99 : []\n",
      "100 : ['2019-07-18']\n"
     ]
    }
   ],
   "source": [
    "for i in raw.index:\n",
    "    path = \"images/\" + str(i+1) + \".jpeg\"\n",
    "    print(i+1,end=' : ')\n",
    "    ll = globalpreprocess(path)\n",
    "    z = [list(set(map(lambda x: x.strip(),img.split('\\n')))) for img in ll]\n",
    "    newstr = set(deep_flatten(z))\n",
    "    date = finding_date(newstr)\n",
    "    raw.loc[i,'predicted_2'] = date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     52\n",
       "False    34\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(raw.converted[raw.converted.notnull()] == raw.predicted_2[z]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.46511627906976"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(raw.converted == raw.predicted_2).value_counts()\n",
    "(52/86)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd attempt accuracy is 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-07-25'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.predicted_2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     2019-05-22\n",
       "10    2019-07-17\n",
       "11    2019-07-02\n",
       "12          None\n",
       "13    2019-07-22\n",
       "         ...    \n",
       "95    2019-06-15\n",
       "96          None\n",
       "97    2019-07-03\n",
       "98          None\n",
       "99    2019-07-18\n",
       "Name: predicted_2, Length: 91, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.predicted_2[9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2019-05-21 None\n",
      "1 2019-07-25 2019-07-25\n",
      "2 2018-09-29 2018-09-29\n",
      "3 2016-10-06 None\n",
      "4 2019-05-29 2019-05-29\n",
      "5 2019-07-03 2019-07-03\n",
      "6 2019-05-23 None\n",
      "7 2019-07-01 None\n",
      "8 2019-05-22 None\n",
      "9 2019-07-17 2019-05-22\n",
      "10 2019-07-02 2019-07-17\n",
      "11 2015-02-08 2019-07-02\n",
      "12 2019-07-22 None\n",
      "13 2019-07-22 2019-07-22\n",
      "14 2019-06-07 None\n",
      "15 2019-05-24 None\n",
      "16 2016-04-15 2019-08-24\n",
      "17 2019-07-20 2016-04-15\n",
      "18 2019-05-20 2019-02-05\n",
      "19 2019-05-29 2019-06-20\n",
      "20 2019-11-22 2019-05-29\n",
      "21 2019-05-07 None\n",
      "22 2019-06-18 2019-05-02\n",
      "23 2019-06-28 2019-06-18\n",
      "24 2019-06-03 2019-06-28\n",
      "25 2019-06-20 2019-06-03\n",
      "26 2019-04-10 2019-06-20\n",
      "27 2019-06-07 2019-07-12\n",
      "28 2019-06-28 2019-06-07\n",
      "29 2019-04-30 2019-06-28\n",
      "30 2019-07-25 2019-04-30\n",
      "31 2017-03-10 None\n",
      "32 2019-06-08 None\n",
      "33 2019-07-14 2019-06-08\n",
      "34 2018-06-30 2019-07-14\n",
      "35 2019-06-27 2018-06-30\n",
      "36 2019-06-25 2019-06-27\n",
      "37 2016-11-24 None\n",
      "38 2019-06-19 2016-11-24\n",
      "39 2019-06-20 None\n",
      "40 2019-05-19 2019-06-19\n",
      "41 2019-05-18 None\n",
      "42 2014-05-22 2019-09-19\n",
      "43 2017-10-01 2019-08-07\n",
      "44 2015-08-22 2019-05-18\n",
      "45 2019-08-09 2014-05-22\n",
      "46 2019-06-27 None\n",
      "47 2019-05-22 2015-08-22\n",
      "48 2019-06-01 2019-08-09\n",
      "49 2019-06-09 2019-06-27\n",
      "50 2019-07-06 2019-07-20\n",
      "51 2018-10-20 2019-06-02\n",
      "52 2018-02-17 2019-07-19\n",
      "53 2019-06-24 2019-06-01\n",
      "54 2019-06-06 2019-07-09\n",
      "55 2019-06-01 2013-07-06\n",
      "56 2019-04-07 None\n",
      "57 2018-08-17 None\n",
      "58 2019-06-01 2018-10-20\n",
      "59 2019-06-26 2018-02-17\n",
      "60 2019-06-14 2013-06-24\n",
      "61 2019-06-25 2019-06-06\n",
      "62 2019-06-19 None\n",
      "63 2019-11-07 2019-06-01\n",
      "64 2019-04-08 2019-06-07\n",
      "65 2019-07-01 2019-07-04\n",
      "66 2019-06-17 None\n",
      "67 2019-06-29 2019-06-01\n",
      "68 2019-05-24 2019-06-28\n",
      "69 2019-03-02 None\n",
      "70 2018-03-18 2019-06-14\n",
      "71 2019-07-24 2019-06-25\n",
      "72 2016-05-26 2019-06-19\n",
      "73 2019-06-29 2019-11-07\n",
      "74 2019-05-17 2019-04-08\n",
      "75 2019-07-01 2019-07-01\n",
      "76 2019-06-15 None\n",
      "77 2019-06-13 None\n",
      "78 2019-08-30 2019-06-29\n",
      "79 2019-06-04 2019-02-05\n",
      "80 2015-04-25 2019-03-02\n",
      "81 2019-07-02 None\n",
      "82 2019-06-15 None\n",
      "83 2019-07-02 None\n",
      "84 2017-12-02 2016-05-26\n",
      "85 2019-07-18 2019-06-29\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i,j in enumerate(raw.converted[raw.converted.notnull()]):\n",
    "    print(i,j , raw.predicted_2[i])\n",
    "    if j == raw.predicted_2[i]:\n",
    "        c+=1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>actual</th>\n",
       "      <th>converted</th>\n",
       "      <th>predicted</th>\n",
       "      <th>predicted_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>May 21, 2019</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25-07-19</td>\n",
       "      <td>2019-07-25</td>\n",
       "      <td>2019-07-25</td>\n",
       "      <td>2019-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Sep 29, 2018</td>\n",
       "      <td>2018-09-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Oct06' 16</td>\n",
       "      <td>2016-10-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5/29/2019</td>\n",
       "      <td>2019-05-29</td>\n",
       "      <td>2019-05-29</td>\n",
       "      <td>2019-05-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>03-Jul-19</td>\n",
       "      <td>2019-07-03</td>\n",
       "      <td>2019-07-03</td>\n",
       "      <td>2019-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>23-05-19</td>\n",
       "      <td>2019-05-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>07-01-19</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>22-05-19</td>\n",
       "      <td>2019-05-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-05-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   images        actual   converted   predicted predicted_2\n",
       "0       1  May 21, 2019  2019-05-21         NaN        None\n",
       "1       2      25-07-19  2019-07-25  2019-07-25  2019-07-25\n",
       "2       3  Sep 29, 2018  2018-09-29         NaN  2018-09-29\n",
       "3       4     Oct06' 16  2016-10-06         NaN        None\n",
       "4       5     5/29/2019  2019-05-29  2019-05-29  2019-05-29\n",
       "5       6     03-Jul-19  2019-07-03  2019-07-03  2019-07-03\n",
       "6       7           NaN         NaN         NaN        None\n",
       "7       8      23-05-19  2019-05-23         NaN        None\n",
       "8       9      07-01-19  2019-07-01         NaN        None\n",
       "9      10      22-05-19  2019-05-22         NaN  2019-05-22"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if raw.predicted_2[6] == (raw.converted[6]):\n",
    "    print('asd')\n",
    "    \n",
    "#if raw.loc[6,'converted'] is None:\n",
    "#    raw.loc[6,'converted'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    }
   ],
   "source": [
    "new_dates = []\n",
    "for i in raw.converted[raw.converted.notnull()]:\n",
    "    if 2010 < int(i[:4]) < 2021:\n",
    "        new_dates.append(i)\n",
    "print(len(new_dates))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in raw.index:\n",
    "    if raw.loc[i,'converted'] == raw.loc[i,'predicted_2'] and :\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
