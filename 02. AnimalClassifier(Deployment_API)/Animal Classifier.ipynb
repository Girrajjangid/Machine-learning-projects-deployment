{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animal Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'dataset/train/'\n",
    "test_dir = 'dataset/validate/'\n",
    "\n",
    "# number of images in the training dataset\n",
    "n_train = 8000\n",
    "\n",
    "# number of images in the validation dataset\n",
    "n_test = 2000\n",
    "\n",
    "# the size of the image (h,w,c)\n",
    "input_shape = (200,200, 3)\n",
    "\n",
    "# size of each mini-batch\n",
    "batch_size = 32\n",
    "\n",
    "# nunmber of training episodes\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the image dataset in a way that is for efficient training\n",
    "### Image Data Generators\n",
    "A naive approach to data loading is to load all the images and transform them up front. This would result in a huge amount of used RAM before training starts. Your machine might not be able to handle this, which would result in crashing kernels. It can also take a very long time depending on the dataset.\n",
    "\n",
    "Instead we can load and transform images required exactly when we need it. This would be when feeding a batch of images to the model during training. \n",
    "\n",
    "Keras provides an optimized method of doing this with the Image Data Generator class. It allows us to load images from a directory efficiently. These generators can also transform the dataset in many other ways to augment it.  Explore these optional transformations to help make your model more general, and improve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define data generators\n",
    "train_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_data_generator  = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# tell the data generators to use data from the train and validation directories\n",
    "train_generator = train_data_generator.flow_from_directory(train_dir,\n",
    "                                                          target_size=(200,200),\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          class_mode='categorical')\n",
    "\n",
    "test_generator = test_data_generator.flow_from_directory(test_dir,\n",
    "                                                          target_size=(200,200),\n",
    "                                                          batch_size=batch_size,\n",
    "                                                          class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking what is in train_generator\n",
    "a,b = next(train_generator)\n",
    "a.shape,b.shape # it create 32 size of batches "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Class Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is useful to have a dictionary of image classes. We can use this dictionary to make our predictions more human-readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a dictionary of class names\n",
    "labels_dictionary = train_generator.class_indices\n",
    "\n",
    "# turn classes dictionary into a list\n",
    "labels_name = list(labels_dictionary.keys())\n",
    "\n",
    "# get the number of classes\n",
    "n_labels = len(labels_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the image classifier model\n",
    "Our model consists of many layers. Images are passed through the model and a set of numbers are outputted. This set of numbers describe the probability of class the image is. We take the largest of these numbers as the most likely class. \n",
    "\n",
    "We will use several types of layers and activations:\n",
    "\n",
    "1. `Conv2D` is a 2-dimensional convolutional layer. It applies filters over the inputted image. This helps the model learn about spatial relationships in the image.\n",
    "2. `ReLu` is a type of non-linear activation function. It helps the model understand which neurons are activating.\n",
    "3. `MaxPooling2D` downsamples its input. We use It to reduce the dimensionality of input. This creates a more abstract form of the input.\n",
    "4. `Flatten` will turn a matrix into a row. Like flattening a muffin into a pancake. We use it so that we can feed the output into dense layers.\n",
    "5. `Dense` is a densely-connected neural network layer. \n",
    "6. `Softmax` is an activation function. We use it to turn the output numbers into a range of 0 and 1. It will also cause all the outputted numbers to add up to 1. This can be interpreted as the decimal probability of a class.\n",
    "\n",
    "Note that the last layer has the same number of neurons as classes. This means that this layer will output 10 numbers, mapping to a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # define the model \n",
    "    # takes in images, convoles them, flattens them, classifies them\n",
    "    # input_shape = (200,200,3)\n",
    "    \n",
    "    model = Sequential()                                                                           \n",
    "    model.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D())\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D())\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D())\n",
    "    \n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(10, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss function and optimizer\n",
    "model = create_model()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we try to find path of each image with labels so we directly feed them into training\n",
    "def get_path_of_imgs(labels, directory):\n",
    "    # Empty list which story the path of classes\n",
    "    class_paths = {}\n",
    "    for each_label in labels:\n",
    "        image_paths = np.array([])\n",
    "        # join  directory + subclass path\n",
    "        class_path = os.path.join(directory, each_label)\n",
    "        # return list of all images in class_path\n",
    "        images = os.listdir(class_path)\n",
    "        for image in images:\n",
    "            # join class_path + each_image\n",
    "            image_path = os.path.join(class_path, image)\n",
    "            # append each images into image_paths\n",
    "            image_paths = np.append(image_paths, image_path)\n",
    "        # append each classes images into class_paths\n",
    "        class_paths[each_label] = image_paths        \n",
    "    \n",
    "    return class_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_of_train = get_path_of_imgs(labels_name, train_dir)\n",
    "img_path_of_test  = get_path_of_imgs(labels_name, test_dir)\n",
    "\n",
    "#pd.DataFrame(img_path_of_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to predict single classes before starting training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_paths, model, input_shape):\n",
    "    images_arr = []\n",
    "    # load images     \n",
    "    for image_path in image_paths:\n",
    "        # load image and turn into array\n",
    "        image_arr = img_to_array(load_img(image_path, target_size=input_shape))\n",
    "\n",
    "        # add the image_arr to the images_arr array\n",
    "        images_arr.append(image_arr)\n",
    "    # turn it into a numpy arrays so that it can be feed into the model as a batch\n",
    "    images = np.array(images_arr)\n",
    "    # make a predictions on the batch\n",
    "    predictions = model.predict(images, batch_size=batch_size)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing only butterfly images and check what model give us output\n",
    "y_cap = predict(img_path_of_train['butterfly'], model,input_shape)\n",
    "\n",
    "# predict accuracy\n",
    "predict_acuracy = lambda x,y_cap : np.count_nonzero(np.argmax(y_cap,axis=1) == x)/len(y_cap)\n",
    "\n",
    "# calling lambda funtion\n",
    "single_class_accuracy = predict_acuracy(labels_dictionary['butterfly'],y_cap)\n",
    "\n",
    "print('Accuracy before training when we feed only butterfly images: ',single_class_accuracy ,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model \n",
    "This model has over 5,000,000 trainable parameter - far too many to set manually. We need to train the model with the training dataset so that the model can to learn the optimal weights that should be used. These weights are the parameter values of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log information for use with tensorboard\n",
    "tensorboard = TensorBoard(log_dir='logs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model using the training data generator\n",
    "history = model.fit_generator(train_generator,\n",
    "                    steps_per_epoch = math.floor(n_train/batch_size),\n",
    "                    validation_data=test_generator,\n",
    "                    validation_steps=math.floor(n_test/batch_size),\n",
    "                    epochs=5,\n",
    "                    callbacks=[tensorboard])                                                                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Model Accuracy After Some Training\n",
    "Let’s examine how well the model performs now that we've trained it a bit. Again, we will determine the model’s accuracy on 1 class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing only butterfly images and check what model give us output\n",
    "y_cap = predict(img_path_of_train['butterfly'], model, input_shape)\n",
    "\n",
    "# calling lambda funtion\n",
    "single_class_accuracy = predict_acuracy(labels_dictionary['butterfly'],y_cap)\n",
    "\n",
    "print('Accuracy after two epochs when we feed only butterfly images: ',single_class_accuracy ,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continue Training the Model\n",
    "Let's continue training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Model Accuracy After Training\n",
    "Now that we've completed training the model, let's examine it's accuracy on 1 class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(class_keys, image_paths, predictions):\n",
    "    \"\"\"\n",
    "    Plots image predictions with the most likely class, and the probabilities of the prediction.\n",
    "        \n",
    "    class_keys: list of class keys\n",
    "    image_paths: path to an image\n",
    "    predictions: predictions of the image_paths\n",
    "    \"\"\"\n",
    "        \n",
    "    for index, image_path in enumerate(image_paths):\n",
    "        # determine the most likely class from the prediction\n",
    "        most_likely_class = np.argmax(predictions[index])\n",
    "\n",
    "        # add class labels for the prediction\n",
    "        # remember that we feed in a batch so we need to grab the first prediction\n",
    "        prediction_classes = [str(class_keys[prob_index]) + \": \" + str(round(prob*100, 4)) + \"%\" for prob_index, prob in enumerate(predictions[index])]\n",
    "\n",
    "        # generate the prediction label\n",
    "        subplot_label = \"Prediction: \" + str(class_keys[most_likely_class]) + \"\\nProbabilities: \" + ', '.join(prediction_classes)\n",
    "\n",
    "        # setup a plot\n",
    "        fig = plt.figure(figsize=(7, 7), tight_layout=True)\n",
    "        fig.set_facecolor('white')\n",
    "        \n",
    "        # load the image\n",
    "        image_pil = load_img(image_path, interpolation='nearest', target_size=(200,200))\n",
    "\n",
    "        # render an image to the plot\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        ax.imshow(image_pil)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(subplot_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loss\n",
    "\n",
    "![Training Loss](assets/loss.png \"Training Loss\")\n",
    "\n",
    "### Training Accuracy\n",
    "![Training Accuracy](assets/acc.png \"Training Accuracy\")\n",
    "\n",
    "### Validation Loss\n",
    "![Validation Loss](assets/val_loss.png \"Validation Loss\")\n",
    "\n",
    "### Validation Accuracy\n",
    "![Validation Accuracy](assets/val_acc.png \"Validation Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "It is useful to know which image predictions were correct and which were wrong. Let’s examine 10 predictions, 1 prediction per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 1 image path per class\n",
    "predict_image_paths = [img_path_of_train[image_path][0] for image_path in img_path_of_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make 1 prediction per class\n",
    "predictions = predict(predict_image_paths, model, input_shape)\n",
    "\n",
    "# plot the image that was predicted\n",
    "#plot_prediction(labels_name, predict_image_paths, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the model for later\n",
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
